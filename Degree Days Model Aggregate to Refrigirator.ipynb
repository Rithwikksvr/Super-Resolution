{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "np.random.seed(30)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from collections import Counter\n",
    "import keras\n",
    "from keras.layers import Conv2D,Dense,Flatten\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days = pd.HDFStore('../Combined Datasets/daily.h5','r')\n",
    "hours = pd.HDFStore('../Combined Datasets/hourly.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_prop = .65\n",
    "v_prop = .2\n",
    "test_prop = .15\n",
    "keys = days.keys()\n",
    "\n",
    "const = 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_data(keys,n_months):\n",
    "    \n",
    "\n",
    "    appliance1 = 'use'\n",
    "    appliance2 = 'refrigerator1'\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    X = np.array([days[i][appliance1].values for i in keys if (appliance1 in days[i].columns and appliance2 in days[i].columns )])[:,:28*n_months]/const\n",
    "    y = np.array([hours[i][appliance2].values for i in keys if (appliance1 in hours[i].columns and appliance2 in hours[i].columns )])[:,:(28*24*n_months)]/const\n",
    "    \n",
    "    X = X.reshape((len(X)*n_months,4,7))\n",
    "    X = np.expand_dims(X,axis=3)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    y = y.reshape((len(y)*n_months,28*24))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return X,y\n",
    "\n",
    "\n",
    "def mae(truth,pred):\n",
    "    return np.mean(const*np.abs((truth-pred)))\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network():\n",
    "    \n",
    "    input_layer = Input(shape=(4,7,1),name=\"Monthly_Matrix\")\n",
    "    input_layer_2 = Input(shape=(1,),name=\"Cooling_Degree_Day_Monthly\")\n",
    "    \n",
    "\n",
    "    op1 = Conv2D(10,kernel_size=(4,1), strides=(1,1),name=\"Filter_4X1\")(input_layer)\n",
    "    \n",
    "    op1 = Flatten()(op1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    op2 = Conv2D(10,kernel_size=(1,7), strides=(1,1),name=\"Filter_1X7\")(input_layer)\n",
    "    \n",
    "    op2 = Flatten()(op2)\n",
    "    \n",
    "    \n",
    "    op3 = Conv2D(10,kernel_size=(1,2),strides=(1,1),name=\"Filter_1X2\")(input_layer)\n",
    "    \n",
    "    op3 = Flatten()(op3)\n",
    "    \n",
    "    op4 = Conv2D(10,kernel_size=(2,1),strides=(1,1),name=\"Filter_2X1\")(input_layer)\n",
    "    \n",
    "    op4 = Flatten()(op4)\n",
    "    \n",
    "    #op5 = Conv2D(20,kernel_size=(3,3),strides=(1,1),padding='same')(input_layer)\n",
    "    \n",
    "    #op5 = Conv2D(20,3,strides=(1,1),padding='same')(input_layer)\n",
    "    \n",
    "    #op5 = Flatten()(op5)\n",
    "    \n",
    "    #op5 =  keras.layers.Dropout(.2)(op5)\n",
    "    \n",
    "    #op5  = Dense(168*4)(op5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    merge_layer = keras.layers.concatenate([op1, op2, op3,op4],name=\"Concatenation_1\")\n",
    "    \n",
    "\n",
    "    \n",
    "    merge_layer =  keras.layers.Dropout(.1)(merge_layer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    merge_layer = keras.layers.concatenate(([merge_layer,input_layer_2]),name=\"Concatenation_2\")\n",
    "    \n",
    "    final_layer = Dense(168*4,name=\"Output_Dense\",activation='relu')(merge_layer)\n",
    "    \n",
    "    \n",
    "    #final_layer = keras.layers.LeakyReLU(alpha=0.01)(final_layer)\n",
    "    \n",
    "    #predictions = Dense(1, activation='sigmoid')(merge_layer)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[input_layer,input_layer_2], outputs=final_layer)\n",
    "\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def empty_dir(dir_name):\n",
    "    for i in os.listdir(dir_name):\n",
    "        os.remove(dir_name+\"/\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_model(train_x,train_y,test_x,test_y,v_x,v_y):\n",
    "    \n",
    "    model = network()\n",
    "    n_epochs = 3000\n",
    "    sgd = keras.optimizers.SGD(lr=0.01)\n",
    "    rmsprop  = keras.optimizers.RMSprop(lr=.001)\n",
    "    adagrad = keras.optimizers.adagrad(lr=.001)\n",
    "    model.compile(optimizer=sgd, loss='mean_squared_error')\n",
    "    \n",
    "    dir_name = 'temp'\n",
    "    empty_dir(dir_name)\n",
    "    \n",
    "    print(\"Started Training!\")\n",
    "    checkpoint = ModelCheckpoint(dir_name+'/single-model-{epoch:04d}.h5', verbose=0, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "    model.fit([train_x,train_temp], train_y, epochs=n_epochs, validation_data=[[v_x,v_temp],v_y], callbacks=[checkpoint], verbose=0)\n",
    "\n",
    "    all_files = os.listdir(dir_name)\n",
    "    all_files.sort()\n",
    "    weights_file = all_files[-1]\n",
    "    \n",
    "    \n",
    "    model.load_weights(dir_name+\"/\"+weights_file)\n",
    "    \n",
    "    \n",
    "    pred_train = model.predict([train_x,train_temp])\n",
    "    pred_v = model.predict([v_x,v_temp])\n",
    "    pred_test = model.predict([test_x,test_temp])\n",
    "    \n",
    "    train_cost = mae(train_y,pred_train)\n",
    "    v_cost = mae(v_y,pred_v)\n",
    "    test_cost = mae(test_y,pred_test)\n",
    "    \n",
    "    return train_cost,v_cost,test_cost\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training!\n",
      "(66.01578, 64.748795, 61.82509)\n",
      "Started Training!\n",
      "(64.823875, 65.957085, 64.765785)\n",
      "Started Training!\n",
      "(64.38653, 63.411476, 71.69811)\n",
      "Started Training!\n",
      "(65.34517, 73.72097, 54.809002)\n",
      "Started Training!\n",
      "(66.917435, 62.248627, 60.391083)\n",
      "Started Training!\n",
      "(67.170204, 67.66694, 52.931362)\n",
      "Started Training!\n",
      "(69.36005, 56.20119, 57.12679)\n",
      "Started Training!\n",
      "(66.4393, 65.79034, 60.072693)\n",
      "Started Training!\n",
      "(67.82009, 62.120583, 58.15696)\n",
      "Started Training!\n",
      "(67.601585, 63.470036, 57.916035)\n"
     ]
    }
   ],
   "source": [
    "n_experiments = 10\n",
    "results_arr = [] \n",
    "for exp in range(n_experiments):\n",
    "    \n",
    "    keys = days.keys()\n",
    "\n",
    "    np.random.seed(exp)\n",
    "    \n",
    "    np.random.shuffle(keys)\n",
    "    \n",
    "    train_homes = keys[:int(len(keys)*train_prop)]\n",
    "    test_homes = keys[int(len(keys)*train_prop):int(-len(keys)*v_prop)]\n",
    "    val_homes = keys[int(-len(keys)*v_prop):]\n",
    "    \n",
    "    train_x,train_y = return_data(train_homes,3)\n",
    "    \n",
    "    test_x,test_y = return_data(test_homes,3)\n",
    "    \n",
    "    v_x,v_y  = return_data(val_homes,3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    vals = [16,18,21]\n",
    "    \n",
    "    \n",
    "    train_temp = np.array(vals*(len(train_x)/3))\n",
    "    \n",
    "    v_temp = np.array(vals*(len(v_x)/3))\n",
    "    \n",
    "    test_temp = np.array(vals*(len(test_x)/3))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    results = fit_model(train_x,train_y,test_x,test_y,v_x,v_y)\n",
    "    \n",
    "    print (results)\n",
    "    \n",
    "    results_arr.append(results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_arr = np.array(results_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66.588  , 64.53361, 59.96929], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results_arr,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
