{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rithwik/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas  as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "np.random.seed(30)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from collections import Counter\n",
    "import keras\n",
    "from keras.layers import Conv2D,Dense,Flatten\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days = pd.HDFStore('../Combined Datasets/daily.h5','r')\n",
    "hours = pd.HDFStore('../Combined Datasets/hourly.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing remaining open files:../Combined Datasets/hourly.h5...done../Combined Datasets/daily.h5...done\n"
     ]
    }
   ],
   "source": [
    "train_prop = .65\n",
    "v_prop = .2\n",
    "test_prop = .15\n",
    "keys = days.keys()\n",
    "\n",
    "const = 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_data(keys,n_months):\n",
    "    \n",
    "\n",
    "    appliance1 = 'use'\n",
    "    appliance2 = 'use'\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    X = np.array([days[i][appliance1].values for i in keys if (appliance1 in days[i].columns and appliance2 in days[i].columns )])[:,:28*n_months]/const\n",
    "    y = np.array([hours[i][appliance2].values for i in keys if (appliance1 in hours[i].columns and appliance2 in hours[i].columns )])[:,:(28*24*n_months)]/const\n",
    "    \n",
    "    X = X.reshape((len(X)*n_months,4,7))\n",
    "    X = np.expand_dims(X,axis=3)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    y = y.reshape((len(y)*n_months,28*24))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return X,y\n",
    "\n",
    "\n",
    "def mae(truth,pred):\n",
    "    return np.mean(const*np.abs((truth-pred)))\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network():\n",
    "    \n",
    "    input_layer = Input(shape=(4,7,1),name=\"Monthly_Matrix\")\n",
    "    \n",
    "    op1 = Conv2D(10,kernel_size=(4,1), strides=(1,1),name=\"Filter_4X1\")(input_layer)\n",
    "    \n",
    "    op1 = Flatten()(op1)\n",
    "    \n",
    "    op2 = Conv2D(10,kernel_size=(1,7), strides=(1,1),name=\"Filter_1X7\")(input_layer)\n",
    "    \n",
    "    op2 = Flatten()(op2)\n",
    "    \n",
    "    op3 = Conv2D(10,kernel_size=(1,2),strides=(1,1),name=\"Filter_1X2\")(input_layer)\n",
    "    \n",
    "    op3 = Flatten()(op3)\n",
    "    \n",
    "    op4 = Conv2D(10,kernel_size=(2,1),strides=(1,1),name=\"Filter_2X1\")(input_layer)\n",
    "    \n",
    "    op4 = Flatten()(op4)\n",
    "    \n",
    "    merge_layer = keras.layers.concatenate([op1, op2, op3,op4],name=\"Concatenation_1\")\n",
    "    \n",
    "    merge_layer =  keras.layers.Dropout(.05)(merge_layer)\n",
    "\n",
    "    \n",
    "    final_layer = Dense(168*4,name=\"Output_Dense\")(merge_layer)\n",
    "    \n",
    "    \n",
    "    final_layer = keras.layers.LeakyReLU(alpha=0.01)(final_layer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[input_layer], outputs=final_layer)\n",
    "\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def empty_dir(dir_name):\n",
    "    for i in os.listdir(dir_name):\n",
    "        os.remove(dir_name+\"/\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(train_x,train_y,test_x,test_y,v_x,v_y):\n",
    "    \n",
    "    model = network()\n",
    "    n_epochs = 2000\n",
    "    sgd = keras.optimizers.SGD(lr=0.001)\n",
    "    rmsprop  = keras.optimizers.RMSprop(lr=.01)\n",
    "    adagrad = keras.optimizers.adagrad(lr=.001)\n",
    "    model.compile(optimizer=sgd, loss='mean_squared_error')\n",
    "    \n",
    "    dir_name = 'temp'\n",
    "    empty_dir(dir_name)\n",
    "    \n",
    "    print(\"Started Training!\")\n",
    "    checkpoint = ModelCheckpoint(dir_name+'/single-model-{epoch:03d}.h5', verbose=0, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "    model.fit(train_x, train_y, epochs=n_epochs, validation_data=[v_x,v_y], callbacks=[checkpoint], verbose=0)\n",
    "\n",
    "    all_files = os.listdir(dir_name)\n",
    "    all_files.sort()\n",
    "    weights_file = all_files[-1]\n",
    "    \n",
    "    model.load_weights(dir_name+\"/\"+weights_file)\n",
    "    \n",
    "    pred_train = model.predict(train_x)\n",
    "    pred_v = model.predict(v_x)\n",
    "    pred_test = model.predict(test_x)\n",
    "\n",
    "    train_cost = mae(train_y,pred_train)\n",
    "    v_cost = mae(v_y,pred_v)\n",
    "    test_cost = mae(test_y,pred_test)\n",
    "    \n",
    "\n",
    "    return train_cost,v_cost,test_cost\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training!\n"
     ]
    }
   ],
   "source": [
    "n_experiments = 10\n",
    "results_arr = [] \n",
    "for exp in range(n_experiments):\n",
    "    \n",
    "    keys = days.keys()\n",
    "\n",
    "    np.random.seed(exp)\n",
    "    \n",
    "    np.random.shuffle(keys)\n",
    "    \n",
    "    train_homes = keys[:int(len(keys)*train_prop)]\n",
    "    test_homes = keys[int(len(keys)*train_prop):int(-len(keys)*v_prop)]\n",
    "    val_homes = keys[int(-len(keys)*v_prop):]\n",
    "    \n",
    "    train_x,train_y = return_data(train_homes,3)\n",
    "    \n",
    "    test_x,test_y = return_data(test_homes,3)\n",
    "    \n",
    "    v_x,v_y  = return_data(val_homes,3)\n",
    "    \n",
    "    \n",
    "    results = fit_model(train_x,train_y,test_x,test_y,v_x,v_y)\n",
    "    \n",
    "    print (results)\n",
    "    \n",
    "    results_arr.append(results)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_arr = np.array(results_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([540.0803 , 584.45496, 534.3034 ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results_arr,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
