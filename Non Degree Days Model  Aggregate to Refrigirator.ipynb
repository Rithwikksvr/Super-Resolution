{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "np.random.seed(30)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from collections import Counter\n",
    "import keras\n",
    "from keras.layers import Conv2D,Dense,Flatten\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days = pd.HDFStore('../Combined Datasets/daily.h5','r')\n",
    "hours = pd.HDFStore('../Combined Datasets/hourly.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_prop = .65\n",
    "v_prop = .2\n",
    "test_prop = .15\n",
    "keys = days.keys()\n",
    "\n",
    "const = 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_data(keys,n_months):\n",
    "    \n",
    "\n",
    "    appliance1 = 'use'\n",
    "    appliance2 = 'refrigerator1'\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    X = np.array([days[i][appliance1].values for i in keys if (appliance1 in days[i].columns and appliance2 in days[i].columns )])[:,:28*n_months]/const\n",
    "    y = np.array([hours[i][appliance2].values for i in keys if (appliance1 in hours[i].columns and appliance2 in hours[i].columns )])[:,:(28*24*n_months)]/const\n",
    "    \n",
    "    X = X.reshape((len(X)*n_months,4,7))\n",
    "    X = np.expand_dims(X,axis=3)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    y = y.reshape((len(y)*n_months,28*24))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return X,y\n",
    "\n",
    "\n",
    "def mae(truth,pred):\n",
    "    return np.mean(const*np.abs((truth-pred)))\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network():\n",
    "    \n",
    "    input_layer = Input(shape=(4,7,1),name=\"Monthly_Matrix\")\n",
    "    \n",
    "    op1 = Conv2D(10,kernel_size=(4,1), strides=(1,1),name=\"Filter_4X1\")(input_layer)\n",
    "    \n",
    "    op1 = Flatten()(op1)\n",
    "    \n",
    "    op2 = Conv2D(10,kernel_size=(1,7), strides=(1,1),name=\"Filter_1X7\")(input_layer)\n",
    "    \n",
    "    op2 = Flatten()(op2)\n",
    "    \n",
    "    op3 = Conv2D(10,kernel_size=(1,2),strides=(1,1),name=\"Filter_1X2\")(input_layer)\n",
    "    \n",
    "    op3 = Flatten()(op3)\n",
    "    \n",
    "    op4 = Conv2D(10,kernel_size=(2,1),strides=(1,1),name=\"Filter_2X1\")(input_layer)\n",
    "    \n",
    "    op4 = Flatten()(op4)\n",
    "    \n",
    "    merge_layer = keras.layers.concatenate([op1, op2, op3,op4],name=\"Concatenation_1\")\n",
    "    \n",
    "    merge_layer =  keras.layers.Dropout(.05)(merge_layer)\n",
    "\n",
    "    \n",
    "    final_layer = Dense(168*4,name=\"Output_Dense\")(merge_layer)\n",
    "    \n",
    "    \n",
    "    final_layer = keras.layers.LeakyReLU(alpha=0.01)(final_layer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[input_layer], outputs=final_layer)\n",
    "\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def empty_dir(dir_name):\n",
    "    for i in os.listdir(dir_name):\n",
    "        os.remove(dir_name+\"/\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(train_x,train_y,test_x,test_y,v_x,v_y):\n",
    "    \n",
    "    model = network()\n",
    "    n_epochs = 3000\n",
    "    sgd = keras.optimizers.SGD(lr=0.01)\n",
    "    rmsprop  = keras.optimizers.RMSprop(lr=.001)\n",
    "    adagrad = keras.optimizers.adagrad(lr=.001)\n",
    "    model.compile(optimizer=sgd, loss='mean_squared_error')\n",
    "    \n",
    "    dir_name = 'temp'\n",
    "    empty_dir(dir_name)\n",
    "    \n",
    "    print(\"Started Training!\")\n",
    "    checkpoint = ModelCheckpoint(dir_name+'/single-model-{epoch:03d}.h5', verbose=0, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "    model.fit(train_x, train_y, epochs=n_epochs, validation_data=[v_x,v_y], callbacks=[checkpoint], verbose=0)\n",
    "\n",
    "    all_files = os.listdir(dir_name)\n",
    "    all_files.sort()\n",
    "    weights_file = all_files[-1]\n",
    "    \n",
    "    model.load_weights(dir_name+\"/\"+weights_file)\n",
    "    \n",
    "    pred_train = model.predict(train_x)\n",
    "    pred_v = model.predict(v_x)\n",
    "    pred_test = model.predict(test_x)\n",
    "\n",
    "    train_cost = mae(train_y,pred_train)\n",
    "    v_cost = mae(v_y,pred_v)\n",
    "    test_cost = mae(test_y,pred_test)\n",
    "    \n",
    "\n",
    "    return train_cost,v_cost,test_cost\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training!\n",
      "(98.683716, 100.99344, 110.751274)\n",
      "Elapsed 254.67761302 Seconds\n",
      "Started Training!\n",
      "(97.23483, 104.35092, 93.54968)\n",
      "Elapsed 314.572471857 Seconds\n",
      "Started Training!\n",
      "(94.77948, 113.368385, 91.344315)\n",
      "Elapsed 323.592671156 Seconds\n",
      "Started Training!\n",
      "(95.84046, 110.97157, 89.86833)\n",
      "Elapsed 261.357469797 Seconds\n",
      "Started Training!\n",
      "(97.904854, 86.81688, 115.514946)\n",
      "Elapsed 327.180912018 Seconds\n",
      "Started Training!\n",
      "(103.44756, 98.77467, 99.815384)\n",
      "Elapsed 277.946527004 Seconds\n",
      "Started Training!\n",
      "(95.2123, 125.08311, 90.14418)\n",
      "Elapsed 320.281327963 Seconds\n",
      "Started Training!\n",
      "(93.670105, 102.797935, 84.2972)\n",
      "Elapsed 243.846777916 Seconds\n",
      "Started Training!\n",
      "(97.39621, 89.889854, 93.15521)\n",
      "Elapsed 281.413692951 Seconds\n",
      "Started Training!\n",
      "(96.87955, 79.1717, 87.18652)\n",
      "Elapsed 268.869931936 Seconds\n"
     ]
    }
   ],
   "source": [
    "n_experiments = 10\n",
    "results_arr = [] \n",
    "for exp in range(n_experiments):\n",
    "    \n",
    "    keys = days.keys()\n",
    "\n",
    "    np.random.seed(exp)\n",
    "    \n",
    "    np.random.shuffle(keys)\n",
    "    \n",
    "    a = time.time()\n",
    "    train_homes = keys[:int(len(keys)*train_prop)]\n",
    "    test_homes = keys[int(len(keys)*train_prop):int(-len(keys)*v_prop)]\n",
    "    val_homes = keys[int(-len(keys)*v_prop):]\n",
    "    \n",
    "    train_x,train_y = return_data(train_homes,3)\n",
    "    \n",
    "    test_x,test_y = return_data(test_homes,3)\n",
    "    \n",
    "    v_x,v_y  = return_data(val_homes,3)\n",
    "    \n",
    "    \n",
    "    results = fit_model(train_x,train_y,test_x,test_y,v_x,v_y)\n",
    "    \n",
    "    print (results)\n",
    "    print(\"Elapsed {} Seconds\".format(time.time()-a))\n",
    "    \n",
    "    results_arr.append(results)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_arr = np.array(results_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97.1049 , 101.22185,  95.5627 ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results_arr,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
